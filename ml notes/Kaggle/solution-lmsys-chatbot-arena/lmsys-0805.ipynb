{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adf75955",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-08-05T07:35:10.241976Z",
     "iopub.status.busy": "2024-08-05T07:35:10.240978Z",
     "iopub.status.idle": "2024-08-05T07:35:10.247863Z",
     "shell.execute_reply": "2024-08-05T07:35:10.245857Z",
     "shell.execute_reply.started": "2024-08-05T07:35:10.241927Z"
    },
    "papermill": {
     "duration": 0.005472,
     "end_time": "2024-08-05T07:46:56.264309",
     "exception": false,
     "start_time": "2024-08-05T07:46:56.258837",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8b34b2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T07:46:56.276637Z",
     "iopub.status.busy": "2024-08-05T07:46:56.275818Z",
     "iopub.status.idle": "2024-08-05T07:47:33.371897Z",
     "shell.execute_reply": "2024-08-05T07:47:33.370774Z"
    },
    "papermill": {
     "duration": 37.109302,
     "end_time": "2024-08-05T07:47:33.379196",
     "exception": false,
     "start_time": "2024-08-05T07:46:56.269894",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/lmsys-packages/triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from triton==2.2.0) (3.13.1)\r\n",
      "Installing collected packages: triton\r\n",
      "Successfully installed triton-2.2.0\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install /kaggle/input/lmsys-packages/triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fcf8393",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T07:47:33.391490Z",
     "iopub.status.busy": "2024-08-05T07:47:33.391156Z",
     "iopub.status.idle": "2024-08-05T07:48:12.877843Z",
     "shell.execute_reply": "2024-08-05T07:48:12.876783Z"
    },
    "papermill": {
     "duration": 39.500635,
     "end_time": "2024-08-05T07:48:12.885247",
     "exception": false,
     "start_time": "2024-08-05T07:47:33.384612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/lmsys-packages/xformers-0.0.24042abc8.d20240802-cp310-cp310-linux_x86_64.whl\r\n",
      "Requirement already satisfied: torch>=1.12 in /opt/conda/lib/python3.10/site-packages (from xformers==0.0.24042abc8.d20240802) (2.1.2)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from xformers==0.0.24042abc8.d20240802) (1.26.4)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.12->xformers==0.0.24042abc8.d20240802) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.12->xformers==0.0.24042abc8.d20240802) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.12->xformers==0.0.24042abc8.d20240802) (1.13.0)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.12->xformers==0.0.24042abc8.d20240802) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.12->xformers==0.0.24042abc8.d20240802) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.12->xformers==0.0.24042abc8.d20240802) (2024.5.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.12->xformers==0.0.24042abc8.d20240802) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.12->xformers==0.0.24042abc8.d20240802) (1.3.0)\r\n",
      "Installing collected packages: xformers\r\n",
      "Successfully installed xformers-0.0.24+042abc8.d20240802\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install /kaggle/input/lmsys-packages/xformers-0.0.24042abc8.d20240802-cp310-cp310-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3b48f75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T07:48:12.898732Z",
     "iopub.status.busy": "2024-08-05T07:48:12.898398Z",
     "iopub.status.idle": "2024-08-05T07:48:13.917168Z",
     "shell.execute_reply": "2024-08-05T07:48:13.916138Z"
    },
    "papermill": {
     "duration": 1.02828,
     "end_time": "2024-08-05T07:48:13.919478",
     "exception": false,
     "start_time": "2024-08-05T07:48:12.891198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp -r /kaggle/input/lmsys-modules-0805 human_pref"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf512cf7",
   "metadata": {
    "papermill": {
     "duration": 0.005932,
     "end_time": "2024-08-05T07:48:13.931613",
     "exception": false,
     "start_time": "2024-08-05T07:48:13.925681",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cec2c5cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T07:48:13.944893Z",
     "iopub.status.busy": "2024-08-05T07:48:13.944621Z",
     "iopub.status.idle": "2024-08-05T07:48:13.951057Z",
     "shell.execute_reply": "2024-08-05T07:48:13.950208Z"
    },
    "papermill": {
     "duration": 0.015402,
     "end_time": "2024-08-05T07:48:13.952927",
     "exception": false,
     "start_time": "2024-08-05T07:48:13.937525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing prepare_test_file.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile prepare_test_file.py\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"/kaggle/input/lmsys-chatbot-arena/test.csv\")\n",
    "df[\"winner_model_a\"] = 1\n",
    "df[\"winner_model_b\"] = 0\n",
    "df[\"winner_tie\"] = 0\n",
    "df.to_parquet(\"test.parquet\", index=False)\n",
    "\n",
    "df[\"response_a\"], df[\"response_b\"] = df[\"response_b\"], df[\"response_a\"]\n",
    "df.to_parquet(\"test_swap.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71411aa9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T07:48:13.965957Z",
     "iopub.status.busy": "2024-08-05T07:48:13.965704Z",
     "iopub.status.idle": "2024-08-05T07:48:16.143477Z",
     "shell.execute_reply": "2024-08-05T07:48:16.142212Z"
    },
    "papermill": {
     "duration": 2.186991,
     "end_time": "2024-08-05T07:48:16.145949",
     "exception": false,
     "start_time": "2024-08-05T07:48:13.958958",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python prepare_test_file.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bbd68d",
   "metadata": {
    "papermill": {
     "duration": 0.005921,
     "end_time": "2024-08-05T07:48:16.158161",
     "exception": false,
     "start_time": "2024-08-05T07:48:16.152240",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference: gemma2-9b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3345731",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T07:48:16.172098Z",
     "iopub.status.busy": "2024-08-05T07:48:16.171805Z",
     "iopub.status.idle": "2024-08-05T07:48:16.179296Z",
     "shell.execute_reply": "2024-08-05T07:48:16.178472Z"
    },
    "papermill": {
     "duration": 0.01722,
     "end_time": "2024-08-05T07:48:16.181370",
     "exception": false,
     "start_time": "2024-08-05T07:48:16.164150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing predict_m0.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile predict_m0.py\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# from xformers.ops.fmha.attn_bias import BlockDiagonalCausalMask\n",
    "from human_pref.models.modeling_gemma2 import Gemma2ForSequenceClassification\n",
    "from human_pref.data.processors import ProcessorPAB\n",
    "from human_pref.data.dataset import LMSYSDataset\n",
    "from human_pref.data.collators import VarlenCollator, ShardedMaxTokensCollator\n",
    "from human_pref.utils import to_device\n",
    "\n",
    "\n",
    "model_name_or_path = \"/kaggle/input/lmsys-checkpoints-0-0805\"\n",
    "csv_path = \"test.parquet\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "processor = ProcessorPAB( tokenizer=tokenizer, max_length=4096, support_system_role=False,)\n",
    "\n",
    "dataset = LMSYSDataset(    csv_file=csv_path,    query=None,    processor=processor,    include_swap=False,    is_parquet=True,)\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=80,\n",
    "    num_workers=4,\n",
    "    collate_fn=ShardedMaxTokensCollator(\n",
    "        max_tokens=8192, base_collator=VarlenCollator()\n",
    "    ),\n",
    ")\n",
    "\n",
    "# model for pipelined inference\n",
    "num_hidden_layers = 42\n",
    "device_map = {\n",
    "    \"model.embed_tokens\": \"cuda:0\",\n",
    "    \"model.norm\": \"cuda:1\",\n",
    "    \"score\": \"cuda:1\",\n",
    "}\n",
    "for i in range(num_hidden_layers // 2):\n",
    "    device_map[f\"model.layers.{i}\"] = \"cuda:0\"\n",
    "for i in range(num_hidden_layers // 2, num_hidden_layers):\n",
    "    device_map[f\"model.layers.{i}\"] = \"cuda:1\"\n",
    "\n",
    "model = Gemma2ForSequenceClassification.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=device_map,\n",
    ")\n",
    "\n",
    "# inv_freq clones for each device\n",
    "config = model.config\n",
    "dim = config.head_dim\n",
    "inv_freq = 1.0 / (\n",
    "    config.rope_theta ** (torch.arange(0, dim, 2, dtype=torch.float32) / dim)\n",
    ")\n",
    "inv_freq0 = inv_freq.to(\"cuda:0\")\n",
    "inv_freq1 = inv_freq.to(\"cuda:1\")\n",
    "\n",
    "\n",
    "# for name, p in model.named_parameters():\n",
    "#     print(name, p.device)\n",
    "# for name, b in model.model.named_buffers():\n",
    "#     print(name, b.device)\n",
    "\n",
    "# pipeline parallelism with two GPUs\n",
    "is_first = True\n",
    "hidden_states = None\n",
    "outs = []\n",
    "for batch in tqdm(dataloader):\n",
    "    for micro_batch in batch:\n",
    "        input_ids = to_device(micro_batch[\"input_ids\"], \"cuda:0\")\n",
    "        seq_info = dict(\n",
    "            cu_seqlens=micro_batch[\"cu_seqlens\"],\n",
    "            position_ids=micro_batch[\"position_ids\"],\n",
    "            max_seq_len=micro_batch[\"max_seq_len\"],\n",
    "            # attn_bias=BlockDiagonalCausalMask.from_seqlens(micro_batch[\"seq_lens\"]),\n",
    "        )\n",
    "        seq_info = to_device(seq_info, \"cuda:0\")\n",
    "        if is_first:\n",
    "            with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "                prev_hidden_states = model.forward_part1(input_ids, seq_info, inv_freq0)\n",
    "            is_first = False\n",
    "            prev_seq_info, prev_hidden_states = to_device(\n",
    "                [seq_info, prev_hidden_states], \"cuda:1\"\n",
    "            )\n",
    "            continue\n",
    "        with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "            logits = model.forward_part2(prev_hidden_states, prev_seq_info, inv_freq1)\n",
    "            hidden_states = model.forward_part1(input_ids, seq_info, inv_freq0)\n",
    "\n",
    "            prev_seq_info, prev_hidden_states = to_device(\n",
    "                [seq_info, hidden_states], \"cuda:1\"\n",
    "            )\n",
    "            outs.append(logits.cpu())\n",
    "\n",
    "# last micro-batch\n",
    "with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "    logits = model.forward_part2(prev_hidden_states, prev_seq_info, inv_freq1)\n",
    "    outs.append(logits.cpu())\n",
    "\n",
    "pred = torch.cat(outs, dim=0)\n",
    "prob = pred.softmax(-1)\n",
    "print(dataset.evaluate(prob.numpy()))\n",
    "\n",
    "np.save('prob_m0.npy', prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9637d917",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T07:48:16.194740Z",
     "iopub.status.busy": "2024-08-05T07:48:16.194475Z",
     "iopub.status.idle": "2024-08-05T07:52:23.868677Z",
     "shell.execute_reply": "2024-08-05T07:52:23.867529Z"
    },
    "papermill": {
     "duration": 247.683645,
     "end_time": "2024-08-05T07:52:23.871171",
     "exception": false,
     "start_time": "2024-08-05T07:48:16.187526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [03:37<00:00, 54.34s/it]\r\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]2024-08-05 07:52:04.758975: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2024-08-05 07:52:04.759123: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2024-08-05 07:52:04.905592: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:17<00:00, 17.05s/it]\r\n",
      "{'log_loss': 3.0968185681481395}\r\n"
     ]
    }
   ],
   "source": [
    "!python predict_m0.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f606a458",
   "metadata": {
    "papermill": {
     "duration": 0.00746,
     "end_time": "2024-08-05T07:52:23.885940",
     "exception": false,
     "start_time": "2024-08-05T07:52:23.878480",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference: llama3-8b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb9d098f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T07:52:23.901304Z",
     "iopub.status.busy": "2024-08-05T07:52:23.900988Z",
     "iopub.status.idle": "2024-08-05T07:52:23.909281Z",
     "shell.execute_reply": "2024-08-05T07:52:23.908332Z"
    },
    "papermill": {
     "duration": 0.01832,
     "end_time": "2024-08-05T07:52:23.911148",
     "exception": false,
     "start_time": "2024-08-05T07:52:23.892828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing predict_m3.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile predict_m3.py\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from xformers.ops.fmha.attn_bias import BlockDiagonalCausalMask\n",
    "from human_pref.models.modeling_llama import LlamaForSequenceClassification\n",
    "from human_pref.data.processors import ProcessorPAB\n",
    "from human_pref.data.dataset import LMSYSDataset\n",
    "from human_pref.data.collators import VarlenCollator, ShardedMaxTokensCollator\n",
    "from human_pref.utils import to_device\n",
    "\n",
    "\n",
    "model_name_or_path = \"/kaggle/input/lmsys-checkpoints-3-0805\"\n",
    "csv_path = \"test_swap.parquet\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "tokenizer.deprecation_warnings[\n",
    "    \"sequence-length-is-longer-than-the-specified-maximum\"\n",
    "] = True\n",
    "processor = ProcessorPAB(\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=4096,\n",
    "    support_system_role=True,\n",
    ")\n",
    "dataset = LMSYSDataset(\n",
    "    csv_file=csv_path,\n",
    "    query=None,\n",
    "    processor=processor,\n",
    "    include_swap=False,\n",
    "    is_parquet=True,\n",
    ")\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=80,\n",
    "    num_workers=4,\n",
    "    collate_fn=ShardedMaxTokensCollator(\n",
    "        max_tokens=8192, base_collator=VarlenCollator()\n",
    "    ),\n",
    ")\n",
    "\n",
    "# model for pipelined inference\n",
    "num_hidden_layers = 32\n",
    "device_map = {\n",
    "    \"model.embed_tokens\": \"cuda:0\",\n",
    "    \"model.norm\": \"cuda:1\",\n",
    "    \"score\": \"cuda:1\",\n",
    "}\n",
    "for i in range(num_hidden_layers // 2):\n",
    "    device_map[f\"model.layers.{i}\"] = \"cuda:0\"\n",
    "for i in range(num_hidden_layers // 2, num_hidden_layers):\n",
    "    device_map[f\"model.layers.{i}\"] = \"cuda:1\"\n",
    "\n",
    "model = LlamaForSequenceClassification.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=device_map,\n",
    ")\n",
    "\n",
    "# inv_freq clones for each device\n",
    "config = model.config\n",
    "dim = config.hidden_size // config.num_attention_heads\n",
    "inv_freq = 1.0 / (\n",
    "    config.rope_theta ** (torch.arange(0, dim, 2, dtype=torch.float32) / dim)\n",
    ")\n",
    "inv_freq0 = inv_freq.to(\"cuda:0\")\n",
    "inv_freq1 = inv_freq.to(\"cuda:1\")\n",
    "\n",
    "\n",
    "# for name, p in model.named_parameters():\n",
    "#     print(name, p.device)\n",
    "# for name, b in model.model.named_buffers():\n",
    "#     print(name, b.device)\n",
    "\n",
    "# pipeline parallelism with two GPUs\n",
    "is_first = True\n",
    "hidden_states = None\n",
    "outs = []\n",
    "for batch in tqdm(dataloader):\n",
    "    for micro_batch in batch:\n",
    "        input_ids = to_device(micro_batch[\"input_ids\"], \"cuda:0\")\n",
    "        seq_info = dict(\n",
    "            cu_seqlens=micro_batch[\"cu_seqlens\"],\n",
    "            position_ids=micro_batch[\"position_ids\"],\n",
    "            max_seq_len=micro_batch[\"max_seq_len\"],\n",
    "            attn_bias=BlockDiagonalCausalMask.from_seqlens(micro_batch[\"seq_lens\"]),\n",
    "        )\n",
    "        seq_info = to_device(seq_info, \"cuda:0\")\n",
    "        if is_first:\n",
    "            with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "                prev_hidden_states = model.forward_part1(input_ids, seq_info, inv_freq0)\n",
    "            is_first = False\n",
    "            prev_seq_info, prev_hidden_states = to_device(\n",
    "                [seq_info, prev_hidden_states], \"cuda:1\"\n",
    "            )\n",
    "            continue\n",
    "        with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "            logits = model.forward_part2(prev_hidden_states, prev_seq_info, inv_freq1)\n",
    "            hidden_states = model.forward_part1(input_ids, seq_info, inv_freq0)\n",
    "\n",
    "            prev_seq_info, prev_hidden_states = to_device(\n",
    "                [seq_info, hidden_states], \"cuda:1\"\n",
    "            )\n",
    "            outs.append(logits.cpu())\n",
    "\n",
    "# last micro-batch\n",
    "with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "    logits = model.forward_part2(prev_hidden_states, prev_seq_info, inv_freq1)\n",
    "    outs.append(logits.cpu())\n",
    "\n",
    "\n",
    "pred = torch.cat(outs, dim=0)\n",
    "prob = pred.softmax(-1)\n",
    "print(dataset.evaluate(prob.numpy()))\n",
    "\n",
    "np.save('prob_m3.npy', prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "476926af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T07:52:23.926448Z",
     "iopub.status.busy": "2024-08-05T07:52:23.926158Z",
     "iopub.status.idle": "2024-08-05T07:55:08.602603Z",
     "shell.execute_reply": "2024-08-05T07:55:08.601458Z"
    },
    "papermill": {
     "duration": 164.686637,
     "end_time": "2024-08-05T07:55:08.604969",
     "exception": false,
     "start_time": "2024-08-05T07:52:23.918332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [02:29<00:00, 37.31s/it]\r\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]2024-08-05 07:54:58.842978: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2024-08-05 07:54:58.843041: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2024-08-05 07:54:58.844612: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:07<00:00,  7.37s/it]\r\n",
      "{'log_loss': 0.7582519183970864}\r\n"
     ]
    }
   ],
   "source": [
    "!python predict_m3.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23685b1",
   "metadata": {
    "papermill": {
     "duration": 0.007865,
     "end_time": "2024-08-05T07:55:08.621163",
     "exception": false,
     "start_time": "2024-08-05T07:55:08.613298",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Make submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53689f6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T07:55:08.638704Z",
     "iopub.status.busy": "2024-08-05T07:55:08.638349Z",
     "iopub.status.idle": "2024-08-05T07:55:08.644781Z",
     "shell.execute_reply": "2024-08-05T07:55:08.643784Z"
    },
    "papermill": {
     "duration": 0.017574,
     "end_time": "2024-08-05T07:55:08.646646",
     "exception": false,
     "start_time": "2024-08-05T07:55:08.629072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing make_submission.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile make_submission.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"test.parquet\")\n",
    "preds = np.average(\n",
    "    [\n",
    "        np.load(\"prob_m0.npy\"),\n",
    "        np.load(\"prob_m3.npy\")[:, [1, 0, 2]],\n",
    "    ],\n",
    "    axis=0,\n",
    "    weights=[2, 1],\n",
    ")\n",
    "sub = pd.DataFrame({\n",
    "    \"id\": df[\"id\"],\n",
    "    \"winner_model_a\": preds[:, 0],\n",
    "    \"winner_model_b\": preds[:, 1],\n",
    "    \"winner_tie\": preds[:, 2],\n",
    "})\n",
    "sub.to_csv(\"submission.csv\", index=False)\n",
    "print(sub.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "854218d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T07:55:08.663595Z",
     "iopub.status.busy": "2024-08-05T07:55:08.663345Z",
     "iopub.status.idle": "2024-08-05T07:55:10.548225Z",
     "shell.execute_reply": "2024-08-05T07:55:10.547319Z"
    },
    "papermill": {
     "duration": 1.895964,
     "end_time": "2024-08-05T07:55:10.550593",
     "exception": false,
     "start_time": "2024-08-05T07:55:08.654629",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  winner_model_a  winner_model_b  winner_tie\r\n",
      "0   136060        0.002276        0.981058    0.016666\r\n",
      "1   211333        0.515450        0.128106    0.356444\r\n",
      "2  1233961        0.084381        0.765794    0.149825\r\n"
     ]
    }
   ],
   "source": [
    "!python make_submission.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cf9faf",
   "metadata": {
    "papermill": {
     "duration": 0.007992,
     "end_time": "2024-08-05T07:55:10.566961",
     "exception": false,
     "start_time": "2024-08-05T07:55:10.558969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    },
    {
     "datasetId": 5496762,
     "sourceId": 9107824,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5496847,
     "sourceId": 9107963,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5496920,
     "sourceId": 9108069,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5493674,
     "sourceId": 9102725,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 497.36558,
   "end_time": "2024-08-05T07:55:10.793819",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-05T07:46:53.428239",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
